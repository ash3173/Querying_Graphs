{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class TemporalGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "class TemporalGraph:\n",
    "    def __init__(self, files):\n",
    "        \"\"\"\n",
    "        Initialize TemporalGraph with a list of JSON files representing graphs at different timestamps.\n",
    "        \"\"\"\n",
    "        self.files = files  # List of JSON file paths\n",
    "\n",
    "    @lru_cache(maxsize=10)  # Cache the last 10 accessed timestamps\n",
    "    def load_graph_at_timestamp(self, timestamp):\n",
    "        \"\"\"\n",
    "        Load the graph for a specific timestamp from JSON and convert it to a NetworkX graph.\n",
    "        \"\"\"\n",
    "        with open(self.files[timestamp], 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return self._json_to_graph(data)\n",
    "\n",
    "    def _json_to_graph(self, data):\n",
    "        \"\"\"\n",
    "        Convert JSON data to a NetworkX graph.\n",
    "        \"\"\"\n",
    "        graph = nx.DiGraph() if data[\"directed\"] else nx.Graph()\n",
    "        \n",
    "        # Add nodes\n",
    "        \n",
    "        for node_type, nodes in data[\"node_values\"].items():\n",
    "            for node in nodes:\n",
    "                node_id = node[-1]  # Assuming the node ID is the last element in the list\n",
    "                node_attributes = dict(zip(data[\"node_types\"][node_type], node))\n",
    "                graph.add_node(node_id, **node_attributes)  # Add the node with its attributes\n",
    "            \n",
    "                \n",
    "        # Add edges\n",
    "        all_edge_types = data[\"relationship_types\"]\n",
    "\n",
    "        for i in data[\"relationship_values\"] :\n",
    "            \n",
    "            if i[0] in all_edge_types :\n",
    "                \n",
    "                attributes = {}\n",
    "                for j in range(len(i)-2) :\n",
    "                    key = all_edge_types[i[0]][j]\n",
    "                    attributes[key] = i[j]\n",
    "\n",
    "                graph.add_edge(i[-2],i[-1],**attributes)\n",
    "            else :\n",
    "                graph.add_edge(i[0],i[1])\n",
    "    \n",
    "        \n",
    "        return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Ensure this is imported properly\n",
    "import tracemalloc\n",
    "import functools\n",
    "\n",
    "def time_and_memory(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Start tracking memory and time\n",
    "        tracemalloc.start()\n",
    "        start_time = time.time()  # Ensure time module is used correctly\n",
    "        \n",
    "        try:\n",
    "            # Call the actual function\n",
    "            result = func(*args, **kwargs)\n",
    "        finally:\n",
    "            # Calculate memory and time usage\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            tracemalloc.stop()\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Time taken by '{func.__name__}': {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Memory used by '{func.__name__}': {current / 1024:.2f} KiB (Current), {peak / 1024:.2f} KiB (Peak)\")\n",
    "\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/supply_chain_export_1000\\\\timestamp_0.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_1.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_2.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_3.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_4.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_5.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_6.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_7.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_8.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_9.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_10.json',\n",
       " 'data/supply_chain_export_1000\\\\timestamp_11.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "# Natural sorting function\n",
    "def natural_sort(files):\n",
    "    # Extract numeric parts from filenames for sorting\n",
    "    return sorted(files, key=lambda x: int(re.search(r'timestamp_(\\d+)', x).group(1)))\n",
    "\n",
    "# Get files and sort\n",
    "files = glob.glob(\"data/supply_chain_export_1000/timestamp_*.json\")\n",
    "files = natural_sort(files)\n",
    "\n",
    "# Initialize TemporalGraph\n",
    "temporal_graph = TemporalGraph(files)\n",
    "temporal_graph.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Parts for product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_and_memory\n",
    "def query_parts_for_product_offering(temporal_graph,timestamp, product_offering_id):\n",
    "    G = temporal_graph.load_graph_at_timestamp(timestamp)\n",
    "    parts = set()\n",
    "    for node, attrs in G.nodes(data=True):\n",
    "        if attrs.get(\"node_type\") == \"Facility\":\n",
    "            if G.has_edge(node, product_offering_id):\n",
    "                edge_data = G[node][product_offering_id]\n",
    "                if edge_data.get(\"relationship_type\") == \"FacilityToProductOfferings\":\n",
    "                    for target, target_attrs in G[node].items():\n",
    "                        if G[node][target].get(\"relationship_type\") == \"PartsToFacility\":\n",
    "                            parts.add(target)\n",
    "\n",
    "    return list(parts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by 'query_parts_for_product_offering': 0.37 seconds\n",
      "Memory used by 'query_parts_for_product_offering': 6876.52 KiB (Current), 8790.33 KiB (Peak)\n",
      "Parts for product offering PO_003: []\n"
     ]
    }
   ],
   "source": [
    "product_offering_id = 'PO_003'  # Replace with actual product offering ID\n",
    "result = query_parts_for_product_offering(temporal_graph,0, product_offering_id)\n",
    "print(f\"Parts for product offering {product_offering_id}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profitable product offering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_and_memory\n",
    "def query_profitable_products(temporal_graph,timestamp, cost_threshold, demand_threshold):\n",
    "    profitable_products = []\n",
    "    G = temporal_graph.load_graph_at_timestamp(timestamp)\n",
    "    for node, attrs in G.nodes(data=True):\n",
    "        if attrs.get(\"node_type\") == \"ProductOffering\":\n",
    "            making_cost = attrs.get(\"cost\", float(\"inf\"))\n",
    "            demand = attrs.get(\"demand\", 0)\n",
    "\n",
    "            if making_cost <= cost_threshold and demand >= demand_threshold:\n",
    "                profitable_products.append((node, making_cost, demand))\n",
    "\n",
    "    return profitable_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by 'query_profitable_products': 0.00 seconds\n",
      "Memory used by 'query_profitable_products': 0.07 KiB (Current), 0.31 KiB (Peak)\n",
      "Profitable Products:\n"
     ]
    }
   ],
   "source": [
    "cost_threshold = 1000\n",
    "demand_threshold = 50\n",
    "\n",
    "profitable_products = query_profitable_products(temporal_graph,0, cost_threshold, demand_threshold)\n",
    "\n",
    "print(\"Profitable Products:\")\n",
    "for product_id, making_cost, demand in profitable_products:\n",
    "    print(f\"Product ID: {product_id}, Making Cost: {making_cost}, Demand: {demand}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
